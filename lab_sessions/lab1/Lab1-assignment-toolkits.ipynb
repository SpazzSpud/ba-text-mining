{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab1-Assignment\n",
    "\n",
    "Copyright: Vrije Universiteit Amsterdam, Faculty of Humanities, CLTL\n",
    "\n",
    "This notebook describes the assignment for Lab 1 of the text mining course. \n",
    "\n",
    "**Points**: each exercise is prefixed with the number of points you can obtain for the exercise.\n",
    "\n",
    "We assume you have worked through the following notebooks:\n",
    "* **Lab1.1-introduction**\n",
    "* **Lab1.2-introduction-to-NLTK**\n",
    "* **Lab1.3-introduction-to-spaCy** \n",
    "\n",
    "In this assignment, you will process an English text (**Lab1-apple-samsung-example.txt**) with both NLTK and spaCy and discuss the similarities and differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credits\n",
    "The notebooks in this block have been originally created by [Marten Postma](https://martenpostma.github.io). Adaptations were made by [Filip Ilievski](http://ilievski.nl)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tip: how to read a file from disk\n",
    "Let's open the file **Lab1-apple-samsung-example.txt** from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tomnorton/Documents/GitHub/ba-text-mining/lab_sessions/lab1/Lab1-apple-samsung-example.txt\n",
      "does path exist? -> True\n"
     ]
    }
   ],
   "source": [
    "cur_dir = Path().resolve() # this should provide you with the folder in which this notebook is placed\n",
    "path_to_file = Path.joinpath(cur_dir, 'Lab1-apple-samsung-example.txt')\n",
    "print(path_to_file)\n",
    "print('does path exist? ->', Path.exists(path_to_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the output from the code cell above states that **does path exist? -> False**, please check that the file **Lab1-apple-samsung-example.txt** is in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of characters 1139\n"
     ]
    }
   ],
   "source": [
    "with open(path_to_file) as infile:\n",
    "    text = infile.read()\n",
    "\n",
    "print('number of characters', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [total points: 4] Exercise 1: NLTK\n",
    "In this exercise, we use NLTK to apply **Part-of-speech (POS) tagging**, **Named Entity Recognition (NER)**, and **Constituency parsing**. The following code snippet already performs sentence splitting and tokenization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_nltk = sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_per_sentence = []\n",
    "for sentence_nltk in sentences_nltk:\n",
    "    sent_tokens = word_tokenize(sentence_nltk)\n",
    "    tokens_per_sentence.append(sent_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use lists to keep track of the output of the NLP tasks. We can hence inspect the output for each task using the index of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTENCE The six phones and tablets affected are the Galaxy S III, running the new Jelly Bean system, the Galaxy Tab 8.9 Wifi tablet, the Galaxy Tab 2 10.1, Galaxy Rugby Pro and Galaxy S III mini.\n",
      "TOKENS ['The', 'six', 'phones', 'and', 'tablets', 'affected', 'are', 'the', 'Galaxy', 'S', 'III', ',', 'running', 'the', 'new', 'Jelly', 'Bean', 'system', ',', 'the', 'Galaxy', 'Tab', '8.9', 'Wifi', 'tablet', ',', 'the', 'Galaxy', 'Tab', '2', '10.1', ',', 'Galaxy', 'Rugby', 'Pro', 'and', 'Galaxy', 'S', 'III', 'mini', '.']\n"
     ]
    }
   ],
   "source": [
    "sent_id = 1\n",
    "print('SENTENCE', sentences_nltk[sent_id])\n",
    "print('TOKENS', tokens_per_sentence[sent_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [point: 1] Exercise 1a: Part-of-speech (POS) tagging\n",
    "Use `nltk.pos_tag` to perform part-of-speech tagging on each sentence.\n",
    "\n",
    "Use `print` to **show** the output in the notebook (and hence also in the exported PDF!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tags_per_sentence = []\n",
    "for tokens in tokens_per_sentence:\n",
    "    pos_tags_per_sentence.append(nltk.pos_tag(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('https', 'NN'), (':', ':'), ('//www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html', 'JJ'), ('Documents', 'NNS'), ('filed', 'VBN'), ('to', 'TO'), ('the', 'DT'), ('San', 'NNP'), ('Jose', 'NNP'), ('federal', 'JJ'), ('court', 'NN'), ('in', 'IN'), ('California', 'NNP'), ('on', 'IN'), ('November', 'NNP'), ('23', 'CD'), ('list', 'NN'), ('six', 'CD'), ('Samsung', 'NNP'), ('products', 'NNS'), ('running', 'VBG'), ('the', 'DT'), ('``', '``'), ('Jelly', 'RB'), ('Bean', 'NNP'), (\"''\", \"''\"), ('and', 'CC'), ('``', '``'), ('Ice', 'NNP'), ('Cream', 'NNP'), ('Sandwich', 'NNP'), (\"''\", \"''\"), ('operating', 'VBG'), ('systems', 'NNS'), (',', ','), ('which', 'WDT'), ('Apple', 'NNP'), ('claims', 'VBZ'), ('infringe', 'VB'), ('its', 'PRP$'), ('patents', 'NNS'), ('.', '.')], [('The', 'DT'), ('six', 'CD'), ('phones', 'NNS'), ('and', 'CC'), ('tablets', 'NNS'), ('affected', 'VBN'), ('are', 'VBP'), ('the', 'DT'), ('Galaxy', 'NNP'), ('S', 'NNP'), ('III', 'NNP'), (',', ','), ('running', 'VBG'), ('the', 'DT'), ('new', 'JJ'), ('Jelly', 'NNP'), ('Bean', 'NNP'), ('system', 'NN'), (',', ','), ('the', 'DT'), ('Galaxy', 'NNP'), ('Tab', 'NNP'), ('8.9', 'CD'), ('Wifi', 'NNP'), ('tablet', 'NN'), (',', ','), ('the', 'DT'), ('Galaxy', 'NNP'), ('Tab', 'NNP'), ('2', 'CD'), ('10.1', 'CD'), (',', ','), ('Galaxy', 'NNP'), ('Rugby', 'NNP'), ('Pro', 'NNP'), ('and', 'CC'), ('Galaxy', 'NNP'), ('S', 'NNP'), ('III', 'NNP'), ('mini', 'NN'), ('.', '.')], [('Apple', 'NNP'), ('stated', 'VBD'), ('it', 'PRP'), ('had', 'VBD'), ('“', 'NNP'), ('acted', 'VBD'), ('quickly', 'RB'), ('and', 'CC'), ('diligently', 'RB'), (\"''\", \"''\"), ('in', 'IN'), ('order', 'NN'), ('to', 'TO'), ('``', '``'), ('determine', 'VB'), ('that', 'IN'), ('these', 'DT'), ('newly', 'RB'), ('released', 'VBN'), ('products', 'NNS'), ('do', 'VBP'), ('infringe', 'VB'), ('many', 'JJ'), ('of', 'IN'), ('the', 'DT'), ('same', 'JJ'), ('claims', 'NNS'), ('already', 'RB'), ('asserted', 'VBN'), ('by', 'IN'), ('Apple', 'NNP'), ('.', '.'), (\"''\", \"''\")], [('In', 'IN'), ('August', 'NNP'), (',', ','), ('Samsung', 'NNP'), ('lost', 'VBD'), ('a', 'DT'), ('US', 'NNP'), ('patent', 'NN'), ('case', 'NN'), ('to', 'TO'), ('Apple', 'NNP'), ('and', 'CC'), ('was', 'VBD'), ('ordered', 'VBN'), ('to', 'TO'), ('pay', 'VB'), ('its', 'PRP$'), ('rival', 'JJ'), ('$', '$'), ('1.05bn', 'CD'), ('(', '('), ('£0.66bn', 'NN'), (')', ')'), ('in', 'IN'), ('damages', 'NNS'), ('for', 'IN'), ('copying', 'VBG'), ('features', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('iPad', 'NN'), ('and', 'CC'), ('iPhone', 'NN'), ('in', 'IN'), ('its', 'PRP$'), ('Galaxy', 'NNP'), ('range', 'NN'), ('of', 'IN'), ('devices', 'NNS'), ('.', '.')], [('Samsung', 'NNP'), (',', ','), ('which', 'WDT'), ('is', 'VBZ'), ('the', 'DT'), ('world', 'NN'), (\"'s\", 'POS'), ('top', 'JJ'), ('mobile', 'NN'), ('phone', 'NN'), ('maker', 'NN'), (',', ','), ('is', 'VBZ'), ('appealing', 'VBG'), ('the', 'DT'), ('ruling', 'NN'), ('.', '.')], [('A', 'DT'), ('similar', 'JJ'), ('case', 'NN'), ('in', 'IN'), ('the', 'DT'), ('UK', 'NNP'), ('found', 'VBD'), ('in', 'IN'), ('Samsung', 'NNP'), (\"'s\", 'POS'), ('favour', 'NN'), ('and', 'CC'), ('ordered', 'VBD'), ('Apple', 'NNP'), ('to', 'TO'), ('publish', 'VB'), ('an', 'DT'), ('apology', 'NN'), ('making', 'VBG'), ('clear', 'JJ'), ('that', 'IN'), ('the', 'DT'), ('South', 'JJ'), ('Korean', 'JJ'), ('firm', 'NN'), ('had', 'VBD'), ('not', 'RB'), ('copied', 'VBN'), ('its', 'PRP$'), ('iPad', 'NN'), ('when', 'WRB'), ('designing', 'VBG'), ('its', 'PRP$'), ('own', 'JJ'), ('devices', 'NNS'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "print(pos_tags_per_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [point: 1] Exercise 1b: Named Entity Recognition (NER)\n",
    "Use `nltk.chunk.ne_chunk` to perform Named Entity Recognition (NER) on each sentence.\n",
    "\n",
    "Use `print` to **show** the output in the notebook (and hence also in the exported PDF!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_tags_per_sentence = []\n",
    "for pos_tags in pos_tags_per_sentence:\n",
    "    ner_tags_per_sentence.append(nltk.chunk.ne_chunk(pos_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tree('S', [('https', 'NN'), (':', ':'), ('//www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html', 'JJ'), ('Documents', 'NNS'), ('filed', 'VBN'), ('to', 'TO'), ('the', 'DT'), Tree('ORGANIZATION', [('San', 'NNP'), ('Jose', 'NNP')]), ('federal', 'JJ'), ('court', 'NN'), ('in', 'IN'), Tree('GPE', [('California', 'NNP')]), ('on', 'IN'), ('November', 'NNP'), ('23', 'CD'), ('list', 'NN'), ('six', 'CD'), Tree('ORGANIZATION', [('Samsung', 'NNP')]), ('products', 'NNS'), ('running', 'VBG'), ('the', 'DT'), ('``', '``'), ('Jelly', 'RB'), Tree('GPE', [('Bean', 'NNP')]), (\"''\", \"''\"), ('and', 'CC'), ('``', '``'), ('Ice', 'NNP'), ('Cream', 'NNP'), ('Sandwich', 'NNP'), (\"''\", \"''\"), ('operating', 'VBG'), ('systems', 'NNS'), (',', ','), ('which', 'WDT'), Tree('PERSON', [('Apple', 'NNP')]), ('claims', 'VBZ'), ('infringe', 'VB'), ('its', 'PRP$'), ('patents', 'NNS'), ('.', '.')]), Tree('S', [('The', 'DT'), ('six', 'CD'), ('phones', 'NNS'), ('and', 'CC'), ('tablets', 'NNS'), ('affected', 'VBN'), ('are', 'VBP'), ('the', 'DT'), Tree('ORGANIZATION', [('Galaxy', 'NNP')]), ('S', 'NNP'), ('III', 'NNP'), (',', ','), ('running', 'VBG'), ('the', 'DT'), ('new', 'JJ'), Tree('PERSON', [('Jelly', 'NNP'), ('Bean', 'NNP')]), ('system', 'NN'), (',', ','), ('the', 'DT'), Tree('ORGANIZATION', [('Galaxy', 'NNP')]), ('Tab', 'NNP'), ('8.9', 'CD'), ('Wifi', 'NNP'), ('tablet', 'NN'), (',', ','), ('the', 'DT'), Tree('ORGANIZATION', [('Galaxy', 'NNP')]), ('Tab', 'NNP'), ('2', 'CD'), ('10.1', 'CD'), (',', ','), Tree('PERSON', [('Galaxy', 'NNP'), ('Rugby', 'NNP'), ('Pro', 'NNP')]), ('and', 'CC'), Tree('PERSON', [('Galaxy', 'NNP'), ('S', 'NNP')]), ('III', 'NNP'), ('mini', 'NN'), ('.', '.')]), Tree('S', [Tree('PERSON', [('Apple', 'NNP')]), ('stated', 'VBD'), ('it', 'PRP'), ('had', 'VBD'), ('“', 'NNP'), ('acted', 'VBD'), ('quickly', 'RB'), ('and', 'CC'), ('diligently', 'RB'), (\"''\", \"''\"), ('in', 'IN'), ('order', 'NN'), ('to', 'TO'), ('``', '``'), ('determine', 'VB'), ('that', 'IN'), ('these', 'DT'), ('newly', 'RB'), ('released', 'VBN'), ('products', 'NNS'), ('do', 'VBP'), ('infringe', 'VB'), ('many', 'JJ'), ('of', 'IN'), ('the', 'DT'), ('same', 'JJ'), ('claims', 'NNS'), ('already', 'RB'), ('asserted', 'VBN'), ('by', 'IN'), Tree('PERSON', [('Apple', 'NNP')]), ('.', '.'), (\"''\", \"''\")]), Tree('S', [('In', 'IN'), Tree('GPE', [('August', 'NNP')]), (',', ','), Tree('PERSON', [('Samsung', 'NNP')]), ('lost', 'VBD'), ('a', 'DT'), Tree('GSP', [('US', 'NNP')]), ('patent', 'NN'), ('case', 'NN'), ('to', 'TO'), Tree('GPE', [('Apple', 'NNP')]), ('and', 'CC'), ('was', 'VBD'), ('ordered', 'VBN'), ('to', 'TO'), ('pay', 'VB'), ('its', 'PRP$'), ('rival', 'JJ'), ('$', '$'), ('1.05bn', 'CD'), ('(', '('), ('£0.66bn', 'NN'), (')', ')'), ('in', 'IN'), ('damages', 'NNS'), ('for', 'IN'), ('copying', 'VBG'), ('features', 'NNS'), ('of', 'IN'), ('the', 'DT'), Tree('ORGANIZATION', [('iPad', 'NN')]), ('and', 'CC'), Tree('ORGANIZATION', [('iPhone', 'NN')]), ('in', 'IN'), ('its', 'PRP$'), Tree('GPE', [('Galaxy', 'NNP')]), ('range', 'NN'), ('of', 'IN'), ('devices', 'NNS'), ('.', '.')]), Tree('S', [Tree('GPE', [('Samsung', 'NNP')]), (',', ','), ('which', 'WDT'), ('is', 'VBZ'), ('the', 'DT'), ('world', 'NN'), (\"'s\", 'POS'), ('top', 'JJ'), ('mobile', 'NN'), ('phone', 'NN'), ('maker', 'NN'), (',', ','), ('is', 'VBZ'), ('appealing', 'VBG'), ('the', 'DT'), ('ruling', 'NN'), ('.', '.')]), Tree('S', [('A', 'DT'), ('similar', 'JJ'), ('case', 'NN'), ('in', 'IN'), ('the', 'DT'), Tree('ORGANIZATION', [('UK', 'NNP')]), ('found', 'VBD'), ('in', 'IN'), Tree('GPE', [('Samsung', 'NNP')]), (\"'s\", 'POS'), ('favour', 'NN'), ('and', 'CC'), ('ordered', 'VBD'), Tree('PERSON', [('Apple', 'NNP')]), ('to', 'TO'), ('publish', 'VB'), ('an', 'DT'), ('apology', 'NN'), ('making', 'VBG'), ('clear', 'JJ'), ('that', 'IN'), ('the', 'DT'), Tree('LOCATION', [('South', 'JJ'), ('Korean', 'JJ')]), ('firm', 'NN'), ('had', 'VBD'), ('not', 'RB'), ('copied', 'VBN'), ('its', 'PRP$'), ('iPad', 'NN'), ('when', 'WRB'), ('designing', 'VBG'), ('its', 'PRP$'), ('own', 'JJ'), ('devices', 'NNS'), ('.', '.')])]\n"
     ]
    }
   ],
   "source": [
    "print(ner_tags_per_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [points: 2] Exercise 1c: Constituency parsing\n",
    "Use the `nltk.RegexpParser` to perform constituency parsing on each sentence.\n",
    "\n",
    "Use `print` to **show** the output in the notebook (and hence also in the exported PDF!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "constituent_parser = nltk.RegexpParser('''\n",
    "NP: {<DT>? <JJ>* <NN>*} # NP\n",
    "P: {<IN>}           # Preposition\n",
    "V: {<V.*>}          # Verb\n",
    "PP: {<P> <NP>}      # PP -> P NP\n",
    "VP: {<V> <NP|PP>*}  # VP -> V (NP|PP)*''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "parse() missing 1 required positional argument: 'chunk_struct'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/44/42krrmz573z3bz3qw2zt33lw0000gn/T/ipykernel_38707/547309188.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconstituency_output_per_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mconstituency_output_per_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRegexpParser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mner_tags_per_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: parse() missing 1 required positional argument: 'chunk_struct'"
     ]
    }
   ],
   "source": [
    "constituency_output_per_sentence = []\n",
    "\n",
    "constituency_output_per_sentence = [constituent_parser.parse(ner_tags_per_sentence)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(constituency_output_per_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augment the RegexpParser so that it also detects Named Entity Phrases (NEP), e.g., that it detects *Galaxy S III* and *Ice Cream Sandwich*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constituent_parser_v2 = nltk.RegexpParser('''\n",
    "NP: {<DT>? <JJ>* <NN>*} # NP\n",
    "P: {<IN>}           # Preposition\n",
    "V: {<V.*>}          # Verb\n",
    "PP: {<P> <NP>}      # PP -> P NP\n",
    "VP: {<V> <NP|PP>*}  # VP -> V (NP|PP)*\n",
    "NEP: {}             # ???''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constituency_v2_output_per_sentence = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(constituency_v2_output_per_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [total points: 1] Exercise 2: spaCy\n",
    "Use Spacy to process the same text as you analyzed with NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html https://www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html NOUN NNS amod LONG\n",
      "\n",
      "\n",
      " \n",
      "\n",
      " SPACE _SP dep \n",
      "\n",
      "\n",
      "Documents document NOUN NNS nsubj Xxxxx\n",
      "filed file VERB VBD ROOT xxxx\n",
      "to to ADP IN prep xx\n",
      "the the DET DT det xxx\n",
      "San San PROPN NNP nmod Xxx\n",
      "Jose Jose PROPN NNP nmod Xxxx\n",
      "federal federal ADJ JJ amod xxxx\n",
      "court court NOUN NN pobj xxxx\n",
      "in in ADP IN prep xx\n",
      "California California PROPN NNP pobj Xxxxx\n",
      "on on ADP IN prep xx\n",
      "November November PROPN NNP pobj Xxxxx\n",
      "23 23 NUM CD nummod dd\n",
      "list list NOUN NN compound xxxx\n",
      "six six NUM CD nummod xxx\n",
      "Samsung Samsung PROPN NNP compound Xxxxx\n",
      "products product NOUN NNS dobj xxxx\n",
      "running run VERB VBG acl xxxx\n",
      "the the DET DT det xxx\n",
      "\" \" PUNCT `` punct \"\n",
      "Jelly Jelly PROPN NNP compound Xxxxx\n",
      "Bean Bean PROPN NNP dobj Xxxx\n",
      "\" \" PUNCT '' punct \"\n",
      "and and CCONJ CC cc xxx\n",
      "\" \" PUNCT `` punct \"\n",
      "Ice Ice PROPN NNP compound Xxx\n",
      "Cream Cream PROPN NNP compound Xxxxx\n",
      "Sandwich sandwich NOUN NN nmod Xxxxx\n",
      "\" \" PUNCT '' punct \"\n",
      "operating operating NOUN NN compound xxxx\n",
      "systems system NOUN NNS conj xxxx\n",
      ", , PUNCT , punct ,\n",
      "which which PRON WDT nsubj xxxx\n",
      "Apple Apple PROPN NNP compound Xxxxx\n",
      "claims claim VERB VBZ nsubj xxxx\n",
      "infringe infringe VERB VBP relcl xxxx\n",
      "its its PRON PRP$ poss xxx\n",
      "patents patent NOUN NNS dobj xxxx\n",
      ". . PUNCT . punct .\n",
      "\n",
      " \n",
      " SPACE _SP dep \n",
      "\n",
      "The the DET DT det Xxx\n",
      "six six NUM CD nummod xxx\n",
      "phones phone NOUN NNS nsubj xxxx\n",
      "and and CCONJ CC cc xxx\n",
      "tablets tablet NOUN NNS conj xxxx\n",
      "affected affect VERB VBN acl xxxx\n",
      "are be AUX VBP ROOT xxx\n",
      "the the DET DT det xxx\n",
      "Galaxy Galaxy PROPN NNP compound Xxxxx\n",
      "S S PROPN NNP compound X\n",
      "III III PROPN NNP attr XXX\n",
      ", , PUNCT , punct ,\n",
      "running run VERB VBG advcl xxxx\n",
      "the the DET DT det xxx\n",
      "new new ADJ JJ amod xxx\n",
      "Jelly Jelly PROPN NNP compound Xxxxx\n",
      "Bean Bean PROPN NNP compound Xxxx\n",
      "system system NOUN NN dobj xxxx\n",
      ", , PUNCT , punct ,\n",
      "the the DET DT det xxx\n",
      "Galaxy Galaxy PROPN NNP compound Xxxxx\n",
      "Tab Tab PROPN NNP nmod Xxx\n",
      "8.9 8.9 NUM CD nummod d.d\n",
      "Wifi Wifi PROPN NNP compound Xxxx\n",
      "tablet tablet NOUN NN appos xxxx\n",
      ", , PUNCT , punct ,\n",
      "the the DET DT det xxx\n",
      "Galaxy Galaxy PROPN NNP compound Xxxxx\n",
      "Tab Tab PROPN NNP conj Xxx\n",
      "2 2 NUM CD compound d\n",
      "10.1 10.1 NUM CD nummod dd.d\n",
      ", , PUNCT , punct ,\n",
      "Galaxy Galaxy PROPN NNP compound Xxxxx\n",
      "Rugby Rugby PROPN NNP compound Xxxxx\n",
      "Pro Pro PROPN NNP conj Xxx\n",
      "and and CCONJ CC cc xxx\n",
      "Galaxy Galaxy PROPN NNP compound Xxxxx\n",
      "S S PROPN NNP compound X\n",
      "III III PROPN NNP conj XXX\n",
      "mini mini NOUN NN appos xxxx\n",
      ". . PUNCT . punct .\n",
      "\n",
      " \n",
      " SPACE _SP dep \n",
      "\n",
      "Apple Apple PROPN NNP nsubj Xxxxx\n",
      "stated state VERB VBD ROOT xxxx\n",
      "it it PRON PRP nsubj xx\n",
      "had have AUX VBD aux xxx\n",
      "“ \" PUNCT `` punct “\n",
      "acted act VERB VBN ccomp xxxx\n",
      "quickly quickly ADV RB advmod xxxx\n",
      "and and CCONJ CC cc xxx\n",
      "diligently diligently ADV RB conj xxxx\n",
      "\" \" PUNCT '' punct \"\n",
      "in in ADP IN prep xx\n",
      "order order NOUN NN pobj xxxx\n",
      "to to PART TO aux xx\n",
      "\" \" PUNCT `` punct \"\n",
      "determine determine VERB VB acl xxxx\n",
      "that that SCONJ IN mark xxxx\n",
      "these these DET DT det xxxx\n",
      "newly newly ADV RB advmod xxxx\n",
      "released release VERB VBN amod xxxx\n",
      "products product NOUN NNS nsubj xxxx\n",
      "do do AUX VBP aux xx\n",
      "infringe infringe VERB VB ccomp xxxx\n",
      "many many ADJ JJ dobj xxxx\n",
      "of of ADP IN prep xx\n",
      "the the DET DT det xxx\n",
      "same same ADJ JJ amod xxxx\n",
      "claims claim NOUN NNS pobj xxxx\n",
      "already already ADV RB advmod xxxx\n",
      "asserted assert VERB VBN acl xxxx\n",
      "by by ADP IN agent xx\n",
      "Apple Apple PROPN NNP pobj Xxxxx\n",
      ". . PUNCT . punct .\n",
      "\" \" PUNCT '' punct \"\n",
      "\n",
      " \n",
      " SPACE _SP dep \n",
      "\n",
      "In in ADP IN prep Xx\n",
      "August August PROPN NNP pobj Xxxxx\n",
      ", , PUNCT , punct ,\n",
      "Samsung Samsung PROPN NNP nsubj Xxxxx\n",
      "lost lose VERB VBD ROOT xxxx\n",
      "a a DET DT det x\n",
      "US US PROPN NNP compound XX\n",
      "patent patent NOUN NN compound xxxx\n",
      "case case NOUN NN dobj xxxx\n",
      "to to ADP IN prep xx\n",
      "Apple Apple PROPN NNP pobj Xxxxx\n",
      "and and CCONJ CC cc xxx\n",
      "was be AUX VBD auxpass xxx\n",
      "ordered order VERB VBN conj xxxx\n",
      "to to PART TO aux xx\n",
      "pay pay VERB VB xcomp xxx\n",
      "its its PRON PRP$ poss xxx\n",
      "rival rival NOUN NN dative xxxx\n",
      "$ $ SYM $ nmod $\n",
      "1.05bn 1.05bn NUM CD dobj d.ddxx\n",
      "( ( PUNCT -LRB- punct (\n",
      "£ £ SYM $ nmod £\n",
      "0.66bn 0.66bn NOUN NN appos d.ddxx\n",
      ") ) PUNCT -RRB- punct )\n",
      "in in ADP IN prep xx\n",
      "damages damage NOUN NNS pobj xxxx\n",
      "for for ADP IN prep xxx\n",
      "copying copy VERB VBG pcomp xxxx\n",
      "features feature NOUN NNS dobj xxxx\n",
      "of of ADP IN prep xx\n",
      "the the DET DT det xxx\n",
      "iPad iPad PROPN NNP pobj xXxx\n",
      "and and CCONJ CC cc xxx\n",
      "iPhone iPhone PROPN NNP conj xXxxxx\n",
      "in in ADP IN prep xx\n",
      "its its PRON PRP$ poss xxx\n",
      "Galaxy Galaxy PROPN NNP compound Xxxxx\n",
      "range range NOUN NN pobj xxxx\n",
      "of of ADP IN prep xx\n",
      "devices device NOUN NNS pobj xxxx\n",
      ". . PUNCT . punct .\n",
      "Samsung Samsung PROPN NNP nsubj Xxxxx\n",
      ", , PUNCT , punct ,\n",
      "which which PRON WDT nsubj xxxx\n",
      "is be AUX VBZ relcl xx\n",
      "the the DET DT det xxx\n",
      "world world NOUN NN poss xxxx\n",
      "'s 's PART POS case 'x\n",
      "top top ADJ JJ amod xxx\n",
      "mobile mobile ADJ JJ amod xxxx\n",
      "phone phone NOUN NN compound xxxx\n",
      "maker maker NOUN NN attr xxxx\n",
      ", , PUNCT , punct ,\n",
      "is be AUX VBZ aux xx\n",
      "appealing appeal VERB VBG ROOT xxxx\n",
      "the the DET DT det xxx\n",
      "ruling ruling NOUN NN dobj xxxx\n",
      ". . PUNCT . punct .\n",
      "\n",
      " \n",
      " SPACE _SP dep \n",
      "\n",
      "A a DET DT det X\n",
      "similar similar ADJ JJ amod xxxx\n",
      "case case NOUN NN nsubj xxxx\n",
      "in in ADP IN prep xx\n",
      "the the DET DT det xxx\n",
      "UK UK PROPN NNP pobj XX\n",
      "found find VERB VBN ROOT xxxx\n",
      "in in ADP IN prep xx\n",
      "Samsung Samsung PROPN NNP poss Xxxxx\n",
      "'s 's PART POS case 'x\n",
      "favour favour NOUN NN pobj xxxx\n",
      "and and CCONJ CC cc xxx\n",
      "ordered order VERB VBD conj xxxx\n",
      "Apple Apple PROPN NNP dobj Xxxxx\n",
      "to to PART TO aux xx\n",
      "publish publish VERB VB xcomp xxxx\n",
      "an an DET DT det xx\n",
      "apology apology NOUN NN dobj xxxx\n",
      "making make VERB VBG acl xxxx\n",
      "clear clear ADJ JJ acomp xxxx\n",
      "that that SCONJ IN mark xxxx\n",
      "the the DET DT det xxx\n",
      "South south ADJ JJ amod Xxxxx\n",
      "Korean korean ADJ JJ amod Xxxxx\n",
      "firm firm NOUN NN nsubj xxxx\n",
      "had have AUX VBD aux xxx\n",
      "not not PART RB neg xxx\n",
      "copied copy VERB VBN ccomp xxxx\n",
      "its its PRON PRP$ poss xxx\n",
      "iPad iPad PROPN NNP dobj xXxx\n",
      "when when SCONJ WRB advmod xxxx\n",
      "designing design VERB VBG advcl xxxx\n",
      "its its PRON PRP$ poss xxx\n",
      "own own ADJ JJ amod xxx\n",
      "devices device NOUN NNS dobj xxxx\n",
      ". . PUNCT . punct .\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text) # insert code here\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_, token.shape_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "small tip: You can use **sents = list(doc.sents)** to be able to use the index to access a sentence like **sents[2]** for the third sentence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [total points: 7] Exercise 3: Comparison NLTK and spaCy\n",
    "We will now compare the output of NLTK and spaCy, i.e., in what do they differ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [points: 3] Exercise 3a: Part of speech tagging\n",
    "Compare the output from NLTK and spaCy regarding part of speech tagging.\n",
    "\n",
    "* To compare, you probably would like to compare sentence per sentence. Describe if the sentence splitting is different for NLTK than for spaCy. If not, where do they differ?\n",
    "* After checking the sentence splitting, select a sentence for which you expect interesting results and perhaps differences. Motivate your choice.\n",
    "* Compare the output in `token.tag` from spaCy to the part of speech tagging from NLTK for each token in your selected sentence. Are there any differences? This is not a trick question; it is possible that there are no differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [points: 2] Exercise 3b: Named Entity Recognition (NER)\n",
    "* Describe differences between the output from NLTK and spaCy for Named Entity Recognition. Which one do you think performs better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [points: 2] Exercise 3c: Constituency/dependency parsing\n",
    "Choose one sentence from the text and run constituency parsing using NLTK and dependency parsing using spaCy.\n",
    "* describe briefly the difference between constituency parsing and dependency parsing\n",
    "* describe differences between the output from NLTK and spaCy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of this notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e515b9c95f63dd6612da07966688393be38b21381b82ddb0c094f6df1d4549e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
